<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VLM Fine-tuning - Albasel</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="/css/style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    
</head>
<body>
    <nav class="topnav">
    <div class="topnav-inner">
        <a href="/" class="topnav-logo">Albasel</a>
        
        <button class="nav-hamburger" id="nav-hamburger" aria-label="Toggle menu">
            <i class="fas fa-bars"></i>
        </button>

        <ul class="topnav-links" id="nav-links">
            <li><a href="/">Home</a></li>
            <li><a href="/posts.html">Posts</a></li>
            <li><a href="/categories.html">Categories</a></li>
            <li><a href="/aboutme.html">About</a></li>
        </ul>

        <button class="theme-toggle" id="theme-toggle" aria-label="Toggle dark mode">
            <i class="fa-solid fa-moon" id="theme-icon"></i>
        </button>
    </div>
</nav>


    <div class="main-content">
        <article class="article">
            <header class="article-header">
                <h1>VLM Fine-tuning</h1>
                <div class="article-meta">
                    
                    <span class="article-category">AgenticAI</span>
                    
                    <time>2026-02-02</time>
                </div>
                
                <img src="https://picsum.photos/seed/agentic-VLMFineTunning/800/400" alt="VLM Fine-tuning" class="article-image" onerror="this.style.display='none'">
                
            </header>

            <div class="post-content">
                <h1>VLM Fine-tuning Summary by Abu-Bakr Soliman</h1>
<h2>Table of Contents</h2>
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#problem-statement">Problem Statement</a></li>
<li><a href="#initial-setup">Initial Setup</a></li>
<li><a href="#vlm-model-selection">VLM Model Selection</a></li>
<li><a href="#enhancing-output-with-vlm">Enhancing Output with VLM</a></li>
<li><a href="#cloud-evaluation">Cloud Evaluation</a></li>
<li><a href="#knowledge-distillation-approach">Knowledge Distillation Approach</a></li>
<li><a href="#fine-tuning-with-llama-factory">Fine-tuning with LLaMA Factory</a></li>
</ul>
<hr>
<h2>Introduction</h2>
<p>Extracting text and data from Arabic documents presents challenges that extend beyond standard scanned text. These documents frequently contain tables, figures, and extraneous noise, which complicate the extraction process.</p>
<p>The current State of the Art employs Vision Language Models (VLMs), which are multi-modal language models capable of understanding images. However, we encounter three primary challenges:</p>
<ul>
<li><strong>Local Models:</strong> The need for models that can run locally.</li>
<li><strong>Budget Constraints:</strong> Maintaining a low-cost solution.</li>
<li><strong>Value Addition:</strong> The model must provide more value than traditional Optical Character Recognition (OCR) methods.</li>
</ul>
<hr>
<h2>Problem Statement</h2>
<h3>Document Complexity</h3>
<p>Arabic documents present unique challenges including:</p>
<ul>
<li>Tables and structured data</li>
<li>Figures and diagrams</li>
<li>Document noise and quality issues</li>
<li>Mixed content types</li>
</ul>
<h3>Project Requirements</h3>
<ul>
<li>Local deployment capability</li>
<li>Cost-effective solution</li>
<li>Performance exceeding traditional OCR</li>
</ul>
<hr>
<h2>Initial Setup</h2>
<h3>Google Colab Setup</h3>
<p>For each PDF file, we extract all images, save them in a specified format, and apply preprocessing steps to each image. The preprocessing steps include:</p>
<ul>
<li><strong>Resize</strong></li>
<li><strong>Contrast Enhancement</strong></li>
</ul>
<hr>
<h2>VLM Model Selection</h2>
<h3>Overview</h3>
<p>We have identified three VLM options for our tasks:</p>
<ul>
<li><strong>Qwen3 VL</strong></li>
<li><strong>Gemma</strong></li>
<li><strong>Lllava</strong></li>
</ul>
<h3>Qwen3 VL</h3>
<p>Abu-Bakr initially tested the Qwen3 VL with 2B parameters, which did not yield satisfactory results. Upon switching to the 8B version, he found that it consistently added and fixed details from the documents an unwanted feature in our case. Additionally, some Chinese characters appeared unexpectedly.</p>
<p><strong>Issues Identified:</strong></p>
<ul>
<li>Unwanted detail additions and corrections</li>
<li>Unexpected Chinese characters in output</li>
<li>Not suitable for our use case</li>
</ul>
<h3>Lllava</h3>
<p>Next, Abu-Bakr experimented with Lllava, noting that while it was faster than Qwen3, it performed poorly with documents containing lengthy content.</p>
<p><strong>Performance Notes:</strong></p>
<ul>
<li>Faster than Qwen3</li>
<li>Poor performance on lengthy documents</li>
<li>Not recommended for our task</li>
</ul>
<h3>Gemma3 (Selected Model)</h3>
<p>Finally, Abu-Bakr tried Gemma3, which preserved all details without adding or altering them, outputting information only when the confidence level was high. Hence, we will use the 4B Instruct version for our task.</p>
<p><strong>Why Gemma3:</strong></p>
<ul>
<li>Preserves all details without additions</li>
<li>High confidence threshold for output</li>
<li>Optimal balance of speed and accuracy</li>
</ul>
<h4>Implementation Code</h4>
<pre class="hljs"><code><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor, Gemma3ForConditionalGeneration
<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-keyword">import</span> requests
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> IPython.display <span class="hljs-keyword">import</span> Image <span class="hljs-keyword">as</span> display

data_dir = <span class="hljs-string">&quot;/content/pdf_images&quot;</span>
model_id = <span class="hljs-string">&quot;google/gemma-3-4b-it&quot;</span>

model = Gemma3ForConditionalGeneration.from_pretrained(
    model_id, dtype=<span class="hljs-string">&quot;auto&quot;</span>, device_map=<span class="hljs-string">&quot;auto&quot;</span>
).<span class="hljs-built_in">eval</span>()

processor = AutoProcessor.from_pretrained(model_id)
</code></pre>
<hr>
<h2>Enhancing Output with VLM</h2>
<h3>Beyond Basic Text Extraction</h3>
<p>If we are utilizing a VLM and incurring additional costs, we should leverage its capabilities to categorize and classify our documents, enriching the output with more information.</p>
<p>This enhancement includes additional metadata in the output JSON, such as:</p>
<ul>
<li>Publishing dates</li>
<li>Document types</li>
<li>Date types</li>
<li>Page numbers</li>
</ul>
<h3>Structured Output Example</h3>
<h4>Prompt Example</h4>
<p>For example, for bank invoices, the JSON structure could look like this:</p>
<pre class="hljs"><code><span class="hljs-punctuation">{</span>
  <span class="hljs-attr">&quot;invoice_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;INV-2026-0023&quot;</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;date&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;2026-02-09&quot;</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;due_date&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;2026-03-09&quot;</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;sender&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">{</span>
    <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;ABC Bank&quot;</span><span class="hljs-punctuation">,</span>
    <span class="hljs-attr">&quot;address&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;123 Finance Street, Cairo, Egypt&quot;</span><span class="hljs-punctuation">,</span>
    <span class="hljs-attr">&quot;tax_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;123456789&quot;</span>
  <span class="hljs-punctuation">}</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;recipient&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">{</span>
    <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Youssef Albasel&quot;</span><span class="hljs-punctuation">,</span>
    <span class="hljs-attr">&quot;address&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;45 Nile Avenue, Cairo, Egypt&quot;</span><span class="hljs-punctuation">,</span>
    <span class="hljs-attr">&quot;customer_id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;CUST-7890&quot;</span>
  <span class="hljs-punctuation">}</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;items&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>
    <span class="hljs-punctuation">{</span>
      <span class="hljs-attr">&quot;description&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Monthly account maintenance&quot;</span><span class="hljs-punctuation">,</span>
      <span class="hljs-attr">&quot;quantity&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span>
      <span class="hljs-attr">&quot;unit_price&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">50</span><span class="hljs-punctuation">,</span>
      <span class="hljs-attr">&quot;currency&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;EGP&quot;</span><span class="hljs-punctuation">,</span>
      <span class="hljs-attr">&quot;total&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">50</span>
    <span class="hljs-punctuation">}</span><span class="hljs-punctuation">,</span>
    <span class="hljs-punctuation">{</span>
      <span class="hljs-attr">&quot;description&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;International transfer fee&quot;</span><span class="hljs-punctuation">,</span>
      <span class="hljs-attr">&quot;quantity&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">2</span><span class="hljs-punctuation">,</span>
      <span class="hljs-attr">&quot;unit_price&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">20</span><span class="hljs-punctuation">,</span>
      <span class="hljs-attr">&quot;currency&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;EGP&quot;</span><span class="hljs-punctuation">,</span>
      <span class="hljs-attr">&quot;total&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">40</span>
    <span class="hljs-punctuation">}</span>
  <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;subtotal&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">90</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;tax&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">{</span>
    <span class="hljs-attr">&quot;rate&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">14</span><span class="hljs-punctuation">,</span>
    <span class="hljs-attr">&quot;amount&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">12.6</span>
  <span class="hljs-punctuation">}</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;total&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">102.6</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;status&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;unpaid&quot;</span><span class="hljs-punctuation">,</span>
  <span class="hljs-attr">&quot;notes&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Please pay by the due date to avoid late fees.&quot;</span>
<span class="hljs-punctuation">}</span>
</code></pre>
<p>The goal is to enrich the output JSON with as much useful information as possible. For a detailed prompt used by Abu-Bakr, refer to <a href="https://sharetext.io/r1zwpwpl">this link</a>.</p>
<h3>Gemma3 Limitations</h3>
<p>Unfortunately, Gemma was unable to extract and provide all the required data successfully.</p>
<hr>
<h2>Cloud Evaluation</h2>
<h3>Evaluating GEMINI</h3>
<p>Next, we evaluated the cloud version, GEMINI, which performed significantly better. If we have training data free of sensitive information, we can utilize it alongside the valuable data obtained from the cloud API to train our local model.</p>
<p><strong>Key Findings:</strong></p>
<ul>
<li>GEMINI cloud API performs significantly better</li>
<li>Can be used as a teacher model for knowledge distillation</li>
<li>Requires non-sensitive data for training</li>
</ul>
<hr>
<h2>Knowledge Distillation Approach</h2>
<h3>What is Knowledge Distillation?</h3>
<p>Knowledge distillation is a machine learning compression technique that transfers knowledge from a large, complex “teacher” model to a smaller, more efficient “student” model.</p>
<p><strong>In Our Context:</strong></p>
<ul>
<li>Teacher Model: GEMINI (cloud-based, high-performance)</li>
<li>Student Model: Gemma3 4B (local, efficient)</li>
<li>Goal: Transfer knowledge to create a local model with near-cloud performance</li>
</ul>
<h3>Data Privacy Concerns</h3>
<p>If we lack safe data to send to an external model, we might need to invest considerable manual effort in labeling all data.</p>
<p><strong>Considerations:</strong></p>
<ul>
<li>Use non-sensitive data for cloud API calls</li>
<li>Manual labeling required for sensitive documents</li>
<li>Balance between automation and data privacy</li>
</ul>
<hr>
<h2>Fine-tuning with LLaMA Factory</h2>
<h3>Overview</h3>
<p>After completing the calls to the teacher model, we now possess the necessary data to format our local VLM’s output JSON for training. LLaMA Factory is a well-known framework for fine-tuning, and we followed its template for data formatting.</p>
<p>During training, we only need to use concise prompts rather than lengthy ones, as the model will learn to generate comprehensive responses.</p>
<h3>Training Task Definition</h3>
<h4>Two-Task Approach</h4>
<p>We utilize two prompts for two distinct tasks:</p>
<pre class="hljs"><code>llm_finetunning_data = []

task_1_message = <span class="hljs-string">&quot;&quot;&quot;
You are a professional OCR Details Extractor.
Your rule to extract: the page markdown content in addition to the structural elements of the document.
Extract the final output into a JSON format.
Do not generate any introduction or conclusion.
&quot;&quot;&quot;</span>.strip()

task_2_message = <span class="hljs-string">&quot;&quot;&quot;
You are a professional OCR Details Extractor.
Your rule to extract the: document classification, source, physical properties, official marks, signatures authorization, routing distribution, attachments references, condition notes, and confidence quality of the document.
Extract the final output into a JSON format.
Do not generate any introduction or conclusion.
&quot;&quot;&quot;</span>.strip()
</code></pre>
<p><strong>Task Separation:</strong></p>
<ul>
<li><strong>Task 1:</strong> Content extraction (text, structure, markdown)</li>
<li><strong>Task 2:</strong> Metadata extraction (classification, properties, quality)</li>
</ul>
<h3>Data Preparation</h3>
<h4>Data Shuffling Considerations</h4>
<p>It is crucial to shuffle our data during the train-test split. However, we should avoid image-level splitting to prevent data leakage, opting instead for PDF-level splitting:</p>
<pre class="hljs"><code>val_pdf_files = [<span class="hljs-string">&#x27;0012.pdf&#x27;</span>, <span class="hljs-string">&#x27;0005.pdf&#x27;</span>, <span class="hljs-string">&#x27;0011.pdf&#x27;</span>]
train_ds = []
val_ds = []
image_paths_set = <span class="hljs-built_in">set</span>()
</code></pre>
<p><strong>Important:</strong> PDF-level splitting prevents data leakage by ensuring images from the same PDF don’t appear in both training and validation sets.</p>
<h4>Training Example Format</h4>
<p>We define a training example for each task, capturing conversations between a human and the model (GPT), associated images, and the output that the LLM should reproduce:</p>
<pre class="hljs"><code>task_1_sft_record = <span class="hljs-punctuation">{</span>
    <span class="hljs-attr">&quot;conversations&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>
        <span class="hljs-punctuation">{</span>
            <span class="hljs-attr">&quot;value&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;&lt;image&gt;&quot;</span> + task_1_message<span class="hljs-punctuation">,</span>
            <span class="hljs-attr">&quot;from&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;human&quot;</span>
        <span class="hljs-punctuation">}</span><span class="hljs-punctuation">,</span>
        <span class="hljs-punctuation">{</span>
            <span class="hljs-attr">&quot;value&quot;</span><span class="hljs-punctuation">:</span> json.dumps(task_1_output<span class="hljs-punctuation">,</span> ensure_ascii=False<span class="hljs-punctuation">,</span> default=str)<span class="hljs-punctuation">,</span>
            <span class="hljs-attr">&quot;from&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;gpt&quot;</span>
        <span class="hljs-punctuation">}</span>
    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span>
    <span class="hljs-attr">&quot;images&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>rec<span class="hljs-punctuation">[</span>&#x27;image_path&#x27;<span class="hljs-punctuation">]</span><span class="hljs-punctuation">]</span>
<span class="hljs-punctuation">}</span>

task_2_sft_record = <span class="hljs-punctuation">{</span>
    <span class="hljs-attr">&quot;conversations&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>
        <span class="hljs-punctuation">{</span>
            <span class="hljs-attr">&quot;value&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;&lt;image&gt;&quot;</span> + task_2_message<span class="hljs-punctuation">,</span>
            <span class="hljs-attr">&quot;from&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;human&quot;</span>
        <span class="hljs-punctuation">}</span><span class="hljs-punctuation">,</span>
        <span class="hljs-punctuation">{</span>
            <span class="hljs-attr">&quot;value&quot;</span><span class="hljs-punctuation">:</span> json.dumps(task_2_output<span class="hljs-punctuation">,</span> ensure_ascii=False<span class="hljs-punctuation">,</span> default=str)<span class="hljs-punctuation">,</span>
            <span class="hljs-attr">&quot;from&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;gpt&quot;</span>
        <span class="hljs-punctuation">}</span>
    <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span>
    <span class="hljs-attr">&quot;images&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span>rec<span class="hljs-punctuation">[</span>&#x27;image_path&#x27;<span class="hljs-punctuation">]</span><span class="hljs-punctuation">]</span>
<span class="hljs-punctuation">}</span>
</code></pre>
<h4>Saving Training Data</h4>
<p>Next, we save our formatted data as JSON files:</p>
<pre class="hljs"><code><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(join(data_dir, <span class="hljs-string">&quot;datasets&quot;</span>, <span class="hljs-string">&quot;llamafactory-ocr-finetune-data&quot;</span>, <span class="hljs-string">&quot;train-v1.json&quot;</span>), <span class="hljs-string">&quot;w&quot;</span>) <span class="hljs-keyword">as</span> dest:
    json.dump(train_ds, dest, ensure_ascii=<span class="hljs-literal">False</span>, default=<span class="hljs-built_in">str</span>)

<span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(join(data_dir, <span class="hljs-string">&quot;datasets&quot;</span>, <span class="hljs-string">&quot;llamafactory-ocr-finetune-data&quot;</span>, <span class="hljs-string">&quot;val-v1.json&quot;</span>), <span class="hljs-string">&quot;w&quot;</span>) <span class="hljs-keyword">as</span> dest:
    json.dump(val_ds, dest, ensure_ascii=<span class="hljs-literal">False</span>, default=<span class="hljs-built_in">str</span>)
</code></pre>
<p>LLaMA Factory requires JSON files with structured training and validation data, so we serialize our data accordingly.</p>
<h3>Environment Setup</h3>
<h4>Fine-tuning Platform</h4>
<p>Abu-Bakr uses <code>vast.ai</code> for fine-tuning, while I will utilize Google colab cuz im poor. We need to install specific versions of the required libraries:</p>
<h4>Required Dependencies</h4>
<pre class="hljs"><code>!pip install transformers==<span class="hljs-number">4.57</span><span class="hljs-number">.6</span>
!pip install optimum==<span class="hljs-number">1.26</span><span class="hljs-number">.0</span>
!pip install datasets==<span class="hljs-number">4.4</span><span class="hljs-number">.0</span>
!pip install torch==<span class="hljs-number">2.8</span><span class="hljs-number">.0</span>
!pip install torchvision==<span class="hljs-number">0.23</span>
!pip install torchaudio==<span class="hljs-number">2.8</span><span class="hljs-number">.0</span>

!git clone --depth <span class="hljs-number">1</span> https://github.com/hiyouga/LlamaFactory.git
!cd LlamaFactory &amp;&amp; git checkout 762b480131908d37736ad9aa3f12e87f8f7e6313
!cd LlamaFactory &amp;&amp; pip install -e .
!cd LlamaFactory &amp;&amp; pip install -r requirements/metrics.txt
</code></pre>
<p><strong>Note:</strong> Specific library versions are required for compatibility.</p>
<h3>LLaMA Factory Configuration</h3>
<h4>Template Configuration</h4>
<p>We need to add our specific template to Llama Factory’s existing templates in <code>LlamaFactory/data/dataset_info.json</code>:</p>
<pre class="hljs"><code><span class="hljs-attr">&quot;ocr_finetune_train&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">{</span>
    <span class="hljs-attr">&quot;file_name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;/workspace/train-v1-edited.json&quot;</span><span class="hljs-punctuation">,</span> 
    <span class="hljs-attr">&quot;formatting&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;sharegpt&quot;</span><span class="hljs-punctuation">,</span>
    <span class="hljs-attr">&quot;columns&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">{</span>
        <span class="hljs-attr">&quot;messages&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;conversations&quot;</span><span class="hljs-punctuation">,</span>
        <span class="hljs-attr">&quot;images&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;images&quot;</span>
    <span class="hljs-punctuation">}</span>
<span class="hljs-punctuation">}</span><span class="hljs-punctuation">,</span>
<span class="hljs-attr">&quot;ocr_finetune_val&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">{</span>
    <span class="hljs-attr">&quot;file_name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;/workspace/val-v1-edited.json&quot;</span><span class="hljs-punctuation">,</span> 
    <span class="hljs-attr">&quot;formatting&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;sharegpt&quot;</span><span class="hljs-punctuation">,</span>
    <span class="hljs-attr">&quot;columns&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">{</span>
        <span class="hljs-attr">&quot;messages&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;conversations&quot;</span><span class="hljs-punctuation">,</span>
        <span class="hljs-attr">&quot;images&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;images&quot;</span>
    <span class="hljs-punctuation">}</span>
<span class="hljs-punctuation">}</span>
</code></pre>
<h4>Training Configuration (YAML)</h4>
<p>We also need to create a YAML file containing the fine-tuning instructions for <code>train_lora</code> in <code>workspace/LlamaFactory/examples/train_lora/ocr_finetune.yaml</code>:</p>
<pre class="hljs"><code><span class="hljs-attr">model:</span>
  <span class="hljs-attr">model_name_or_path:</span> <span class="hljs-string">google/gemma-3-4b-it</span>
  <span class="hljs-attr">use_fast_tokenizer:</span> <span class="hljs-literal">false</span>
  <span class="hljs-attr">cache_dir:</span> <span class="hljs-string">/workspace/cache</span>
  <span class="hljs-attr">trust_remote_code:</span> <span class="hljs-literal">true</span>

<span class="hljs-attr">method:</span>
  <span class="hljs-attr">stage:</span> <span class="hljs-string">sft</span>
  <span class="hljs-attr">do_train:</span> <span class="hljs-literal">true</span>
  <span class="hljs-attr">finetuning_type:</span> <span class="hljs-string">lora</span>
  <span class="hljs-attr">lora_rank:</span> <span class="hljs-number">96</span>
  <span class="hljs-attr">lora_target:</span> <span class="hljs-string">all</span>

<span class="hljs-attr">dataset:</span>
  <span class="hljs-attr">dataset:</span> <span class="hljs-string">ocr_finetune_train</span>
  <span class="hljs-attr">eval_dataset:</span> <span class="hljs-string">ocr_finetune_val</span>
  <span class="hljs-attr">template:</span> <span class="hljs-string">gemma3</span>
  <span class="hljs-attr">cutoff_len:</span> <span class="hljs-number">12000</span>
  <span class="hljs-attr">overwrite_cache:</span> <span class="hljs-literal">true</span>
  <span class="hljs-attr">preprocessing_num_workers:</span> <span class="hljs-number">16</span>

<span class="hljs-attr">output:</span>
  <span class="hljs-attr">resume_from_checkpoint:</span> <span class="hljs-string">/workspace/ocr-models-gemma-3-4b-it/checkpoint-100</span>
  <span class="hljs-attr">output_dir:</span> <span class="hljs-string">/workspace/ocr-models-gemma-3-4b-it/</span>
  <span class="hljs-attr">logging_steps:</span> <span class="hljs-number">25</span>
  <span class="hljs-attr">save_steps:</span> <span class="hljs-number">50</span>
  <span class="hljs-attr">plot_loss:</span> <span class="hljs-literal">true</span>

<span class="hljs-attr">train:</span>
  <span class="hljs-attr">per_device_train_batch_size:</span> <span class="hljs-number">1</span>
  <span class="hljs-attr">gradient_accumulation_steps:</span> <span class="hljs-number">8</span>
  <span class="hljs-attr">learning_rate:</span> <span class="hljs-number">1.0e-4</span>
  <span class="hljs-attr">num_train_epochs:</span> <span class="hljs-number">20.0</span>
  <span class="hljs-attr">lr_scheduler_type:</span> <span class="hljs-string">cosine</span>
  <span class="hljs-attr">warmup_ratio:</span> <span class="hljs-number">0.1</span>
  <span class="hljs-attr">bf16:</span> <span class="hljs-literal">true</span>
  <span class="hljs-attr">ddp_timeout:</span> <span class="hljs-number">180000000</span>

<span class="hljs-attr">eval:</span>
  <span class="hljs-attr">per_device_eval_batch_size:</span> <span class="hljs-number">1</span>
  <span class="hljs-attr">eval_strategy:</span> <span class="hljs-string">steps</span>
  <span class="hljs-attr">eval_steps:</span> <span class="hljs-number">50</span>

<span class="hljs-attr">report_to:</span> <span class="hljs-string">wandb</span>
<span class="hljs-attr">run_name:</span> <span class="hljs-string">yt-ocr-finetune-llamafactory</span>
</code></pre>
<p><strong>Key Configuration Parameters:</strong></p>
<ul>
<li><strong>LoRA Rank:</strong> 96 (controls adapter size)</li>
<li><strong>Batch Size:</strong> 1 per device with gradient accumulation of 8</li>
<li><strong>Learning Rate:</strong> 1.0e-4 with cosine scheduler</li>
<li><strong>Epochs:</strong> 20</li>
<li><strong>Checkpoint Frequency:</strong> Every 50 steps</li>
</ul>
<h3>Training Execution</h3>
<h4>Starting Training</h4>
<p>Finally, we log in using Weights and Biases (wandb) and initiate training with our YAML file:</p>
<pre class="hljs"><code>!<span class="hljs-built_in">cd</span> LlamaFactory &amp;&amp; <span class="hljs-built_in">export</span> DISABLE_VERSION_CHECK=1 &amp;&amp; llamafactory-cli train /workspace/LLaMA-Factory/examples/train_lora/ocr_finetune.yaml
</code></pre>
<h3>Next Steps</h3>
<p>After successful fine-tuning:</p>
<ol>
<li>Evaluate the model on held-out test data</li>
<li>Compare performance with baseline Gemma3</li>
<li>Test on real-world Arabic documents</li>
<li>Iterate on prompt engineering if needed</li>
<li>Consider merging LoRA adapters for deployment</li>
</ol>
<hr>
<h2>Resources</h2>
<ul>
<li><strong>LLaMA Factory:</strong> <a href="https://github.com/hiyouga/LlamaFactory">https://github.com/hiyouga/LlamaFactory</a></li>
<li><strong>Gemma Models:</strong> <a href="https://huggingface.co/google/gemma-3-4b-it">https://huggingface.co/google/gemma-3-4b-it</a></li>
<li><strong>Detailed Prompt:</strong> <a href="https://sharetext.io/r1zwpwpl">https://sharetext.io/r1zwpwpl</a></li>
<li><strong>Weights &amp; Biases:</strong> <a href="https://wandb.ai">https://wandb.ai</a></li>
</ul>
<hr>
<p><em>Document created: 2026-02-02</em><br>
<em>Author: Abu-Bakr Soliman</em></p>

            </div>

            <footer class="article-footer">
                <a href="/posts.html"><i class="fas fa-arrow-left"></i> All Posts</a>
                <a href="/">Home</a>
            </footer>
        </article>
    </div>

    <script>
    // Theme
    const toggleBtn = document.getElementById('theme-toggle');
    const themeIcon = document.getElementById('theme-icon');
    function setTheme(m) {
        document.body.classList.toggle('dark-mode', m === 'dark');
        themeIcon.className = m === 'dark' ? 'fa-solid fa-sun' : 'fa-solid fa-moon';
        localStorage.setItem('theme', m);
    }
    toggleBtn.addEventListener('click', () => setTheme(document.body.classList.contains('dark-mode') ? 'light' : 'dark'));
    if (localStorage.getItem('theme') === 'dark') setTheme('dark');

    document.getElementById('nav-hamburger').addEventListener('click', () => {
        document.getElementById('nav-links').classList.toggle('open');
    });

    // Copy buttons for code blocks
    document.querySelectorAll('pre.hljs').forEach(pre => {
        const wrapper = document.createElement('div');
        wrapper.className = 'code-wrapper';
        pre.parentNode.insertBefore(wrapper, pre);
        wrapper.appendChild(pre);

        const btn = document.createElement('button');
        btn.className = 'copy-btn';
        btn.textContent = 'Copy';
        wrapper.appendChild(btn);

        btn.addEventListener('click', () => {
            const code = pre.querySelector('code');
            navigator.clipboard.writeText(code ? code.textContent : pre.textContent);
            btn.textContent = 'Copied!';
            setTimeout(() => btn.textContent = 'Copy', 1500);
        });
    });
    </script>
    
</body>
</html>
